= Spike Control
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]

[%autowidth.spread,cols="a,a"]
|===
>s| Policy Name | Spike Control
>s|Summary      | Regulates API traffic
>s|Category | Quality of Service
>s| First Mule version available | v4.1.0
.4+>.^s| Returned Status Codes |

[%autowidth.spread,cols="a,a"]
!===
.3+>.^! 429 ! The number of requests exceeded the configured limit! Request is rejected after specified number of reattempts.
! This status code applies to HTTP APIs.
.3+>.^! 400 ! The number of requests exceeded the configured limit! Request is rejected after specified number of reattempts.
! This status code applis to WSDL APIs that use SOAP v1.2.
.3+>.^! 500 ! The number of requests exceeded the configured limit! Request is rejected after specified number of reattempts.
! This status code applis to WSDL APIs that use SOAP v1.1.
!===

|===

The Spike Control policy regulates your API request traffic by limiting the number of messages processed by an API. The policy ensures that the number of messages processed within a specified time does not exceed the limit that you configure. If the number is exceeded, the request is queued for retry based on you have configured the policy.

== How This Policy Works

The Spike Control policy uses the  _Sliding Window Algorithm_ to display only that portion of information that matches the requirements that you configure in the policy, for reducing spikes in traffic and protecting the Mule runtime engine (Mule) instance. The window self-adjusts its display size to accommodate results over time. 

If the current window has no remaining request quota, without closing the connection to the client, the Spike Control policy allows requests to be queued for processing later. For your policy to queue the requests, you must configure the policy parameters, as shown in the following example:

* `Time Period`: 1 second
* `Number of Reqs`: 2
* `Delay Time in Milliseconds`: 499 milliseconds
* `Delay Attempts`: 1
* `Queuing Limit`: 5

Queuing a request requires retaining a thread and an HTTP connection. When you specify a `Queuing Limit` for the policy, the parameter protects the server from running out of resources and ensures that the API does not fail in case of an attack.

== Request Timelines

The following diagram illustrates the lifespan of each request accepted by the algorithm, using the configuration defined in the previous section:

image::spike-control.png[Accepted,Rejected, Queued Requests Timeline]

. The first two requests are accepted and the available quota is now 0. 
+
The quota increases to 1 after one second (the `window size` value) passes from request #1.
. Request #3 arrives. 
+
Because no quota is available, the request is queued for 499 milliseconds. Request #3 consumes the quota that was available after request #2.
. Request #4 arrives. 
+
Because there still is no quota available, the request is queued for 499 milliseconds.
. Shortly before request #3 is retried, request #1 ages a second and its quota is released, because it falls out of the window.
. Quota is now 1, and request #3 is reprocessed successfully. 
+
Quota returns to 0 until request #2 ages 1 second.
. Request #4 delay concludes and it must be reprocessed.
Request #4 is rejected. Requests #2 and #3 have not aged enough because there are no more delays.
. Request #5 arrives.
+
Because request #2 has already aged more than a second, the request is accepted.

This example illustrates request delays and how queuing regulates spikes in traffic. In high-contention scenarios, the backend continues to function properly (it serves no more than X requests in the last Y milliseconds).

Users querying the API might still see their requests being served, but with higher latency. The exact configuration for the policy depends exclusively on your API and its throughput.

== Configuring Policy Parameters

When you apply the policy to your API from the UI, the following parameters are displayed:

[%header%autowidth.spread,cols="a,a,a"]
|===
| Element | Description | Required
| Number of Reqs | The number of requests allowed (in milliseconds) in the specified window | Yes
|Time Period | The number of milliseconds, within which a request must be processed | Yes
| Delay Time in Milliseconds | The amount of time for which each request is retained before retrying (in milliseconds) in case there is no quota remaining | Yes
| Delay Attempts | The number of times a request is retried before it is rejected | Yes
| Queuing Limit | The number of requests that can be queued at the any given time | No
| Expose headers | Enabled only for internal APIs, allows the policy to return information about the algorithm behavior in the X-RateLimit headers | No
| Method & Resource conditions | The option to add configurations to only a select few or all methods and resources of the API | Yes
|===

The Spike Control policy does not perform quota enforcement. The configuration parameters are restricted to protect the API and backend. Therefore, to ensure maximum performance, configure these parameters to the lowest possible value. 

To enforce request quotas, see the xref:rate-limiting-and-throttling-sla-based-policies.adoc[SLA-based Rate Limiting policy] and xref:rate-limiting.adoc[Rate Limiting policy].

== FAQ

*When does the sliding window start?*

The window starts with the first request after the policy is successfully applied.

*What type of window does the algorithm use?*

It uses a sliding window. You can think of it as a way to keep track of what has happened in the last 'Y' milliseconds _(being 'Y' the amount of time you configure in the policy)_.

*What happens when the quota is exhausted?*

When the request quota is exhausted, the Spike Control queues the request and retries as configured, it rejects the request if after every retry there is still no quota left. If your window configuration is 'X' requests in 'Y' milliseconds, there is no quota available until the first request in that window has aged 'Y' milliseconds. Immediately after that event happens, the system has a quota of 1 (one) until the second request ages 'Y' milliseconds and so forth.

*Can I configure multiple windows?*

No, the intent of Spike Control is to ensure the backend server does not serve more that requests than it can handle. If you need accountability, you should use either Rate Limiting SLA or Rate Limit.

[[response-header]]
*What does each response header mean?*

Each response header has information about the current state of the request:

* X-Ratelimit-Remaining: The amount of available quota
* X-Ratelimit-Limit: The maximum available requests per window
* X-Ratelimit-Reset: The remaining time, in milliseconds, until the oldest request ages enough to fall outside of the sliding window. If there is still quota available, then this header is 0 (zero), as the algorithm can still serve new requests.

MuleSoft advises that you expose these headers only if the API is used within the organization. In a public API scenario, this data can be used maliciously to invoke spikes in traffic that leaves your API without any quota left.

*Can I configure Spike Control in a Mule cluster?*

No, the policy protects a Mule instance. If you do have a Mule cluster in your architecture, use Spike Control to protect each instance separately.

*When should I use Rate Limiting instead of Rate Limiting SLA or Spike Control?*

Use Rate Limiting and Rate Limiting-SLA policies for accountability and to enforce a hard limit to a group (using the identifier in Rate Limiting) or to a client application (using Rate Limiting-SLA). If you want to protect your backend, use the Spike Control policy instead.


== See Also

* xref:rate-limiting-and-throttling.adoc[Rate Limiting Policy]





